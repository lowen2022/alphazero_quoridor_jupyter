{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Quoridor Game with MCTS Implementation\n",
        "# This module implements the Quoridor board game for two players, including Monte Carlo Tree Search (MCTS) for AI moves.\n",
        "# The game supports pawn movement and wall placement, with a graphical policy visualization.\n"
      ],
      "metadata": {
        "id": "4X_agL1ZyfUL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 1: Game State Management\n",
        "\"\"\"\n",
        "Module 1: GameState\n",
        "Purpose: Manages the state of the Quoridor game, including player positions, walls, and the game board.\n",
        "Key Features:\n",
        "- Initializes the game board with a given size and number of walls.\n",
        "- Encodes the game state for AI processing.\n",
        "- Provides a method to create a copy of the current state.\n",
        "- Represents the board as a 2D array where:\n",
        "  - 0: Empty path\n",
        "  - 1: Wall\n",
        "  - 2: Player 1\n",
        "  - 3: Player 2\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qlcDZrNg0qWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7_EQiRvxqSMu"
      },
      "outputs": [],
      "source": [
        "class GameState:\n",
        "    def __init__(self, size: int = 9, wall_count: int = 10, copy_state: 'GameState' = None):\n",
        "        self.size = size\n",
        "        if copy_state:\n",
        "            self.size = copy_state.size\n",
        "            self.player_positions = copy_state.player_positions.copy()\n",
        "            self.remaining_walls = copy_state.remaining_walls.copy()\n",
        "            self.wall_grid = copy_state.wall_grid.copy()\n",
        "            self.game_board = copy_state.game_board.copy()\n",
        "            self.turn_count = copy_state.turn_count\n",
        "        else:\n",
        "            self.player_positions = np.array([[0, size // 2], [size - 1, size // 2]])\n",
        "            self.remaining_walls = np.array([wall_count, wall_count])\n",
        "            self.wall_grid = np.zeros((2, size - 1, size - 1), dtype=np.int8)\n",
        "            self.game_board = self._create_board()\n",
        "            self.turn_count = 0\n",
        "\n",
        "    def _create_board(self):\n",
        "        \"\"\"Initializes a 2N-1 x 2N-1 board with walls and player positions.\"\"\"\n",
        "        board = np.zeros((self.size * 2 - 1, self.size * 2 - 1), dtype=np.int8)\n",
        "        board[1::2, 1::2] = 1  # Wall intersections\n",
        "        board[self.player_positions[0, 0] * 2, self.player_positions[0, 1] * 2] = 2  # Player 1\n",
        "        board[self.player_positions[1, 0] * 2, self.player_positions[1, 1] * 2] = 3  # Player 2\n",
        "        return board\n",
        "\n",
        "    def duplicate(self):\n",
        "        \"\"\"Creates a deep copy of the current game state.\"\"\"\n",
        "        return GameState(copy_state=self)\n",
        "\n",
        "    def encode_state(self, player):\n",
        "        \"\"\"\n",
        "        Encodes the game state into a 4xNxN array for AI input.\n",
        "        Channels:\n",
        "        - 0: Current player's position\n",
        "        - 1: Opponent's position\n",
        "        - 2: Horizontal walls\n",
        "        - 3: Vertical walls\n",
        "        Flips the board vertically for player 1.\n",
        "        \"\"\"\n",
        "        encoded = np.zeros((4, self.size, self.size), dtype=np.float32)\n",
        "        encoded[player, self.player_positions[0, 0], self.player_positions[0, 1]] = 1\n",
        "        encoded[1 - player, self.player_positions[1, 0], self.player_positions[1, 1]] = 1\n",
        "        if player == 1:\n",
        "            encoded[:2, :, :] = np.flip(encoded[:2, :, :], axis=1)\n",
        "        wall_1 = self.wall_grid[0, :, :] if player == 0 else np.flipud(self.wall_grid[1, :, :])\n",
        "        wall_2 = self.wall_grid[1, :, :] if player == 0 else np.flipud(self.wall_grid[0, :, :])\n",
        "        encoded[2, :, :] = np.pad(wall_1 == 1, ((0, 1), (0, 1)), 'constant')\n",
        "        encoded[3, :, :] = np.pad(wall_2 == 1, ((0, 1), (0, 1)), 'constant')\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2: Game Rules and Logic\n",
        "\"\"\"\n",
        "Module 2: QuoridorGame\n",
        "Purpose: Implements the rules and mechanics of the Quoridor game.\n",
        "Key Features:\n",
        "- Validates moves and wall placements.\n",
        "- Calculates the shortest path to the goal using A* algorithm.\n",
        "- Manages game state transitions and win conditions.\n",
        "- Provides valid actions for the current player.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JX1O3qfa02bV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vwSMf7_1qSMv"
      },
      "outputs": [],
      "source": [
        "\n",
        "class QuoridorGame:\n",
        "    def __init__(self, board_size, total_walls):\n",
        "        self.board_size = board_size\n",
        "        self.total_walls = total_walls\n",
        "\n",
        "    def new_game(self):\n",
        "        \"\"\"Returns the initial game state.\"\"\"\n",
        "        return GameState(self.board_size, self.total_walls)\n",
        "\n",
        "    def _find_shortest_path(self, state: GameState, player):\n",
        "        \"\"\"\n",
        "        Uses A* algorithm to find the shortest path to the goal.\n",
        "        Returns the distance or -1 if no path exists.\n",
        "        Heuristic: Manhattan distance to the goal row.\n",
        "        \"\"\"\n",
        "        board = state.game_board\n",
        "        start = state.player_positions[player] * 2\n",
        "        priority_queue = [(2 * self.board_size - 2, 0, 0, start)]\n",
        "        visited = np.zeros((2 * self.board_size - 1, 2 * self.board_size - 1), dtype=np.int8)\n",
        "        counter = 0\n",
        "        while priority_queue:\n",
        "            _, _, steps, pos = heapq.heappop(priority_queue)\n",
        "            if pos[0] < 0 or pos[0] > 2 * self.board_size - 2 or pos[1] < 0 or pos[1] > 2 * self.board_size - 2:\n",
        "                continue\n",
        "            if board[*pos] == 1 or visited[*pos] == 1:\n",
        "                continue\n",
        "            if pos[0] == (2 * self.board_size - 2) * (1 - player):\n",
        "                return steps\n",
        "            visited[*pos] = 1\n",
        "            for direction in [[-1, 0], [1, 0], [0, -1], [0, 1]]:\n",
        "                new_pos = pos + direction\n",
        "                heuristic = (2 * self.board_size - 2 - new_pos[0]) * (1 - player) + (2 * new_pos[0]) * player\n",
        "                heapq.heappush(priority_queue, (heuristic + steps + 1, counter := counter + 1, steps + 1, new_pos))\n",
        "        return -1\n",
        "\n",
        "    def is_wall_valid(self, state: GameState):\n",
        "        \"\"\"Checks if walls allow a path to the goal for both players.\"\"\"\n",
        "        return self._find_shortest_path(state, 0) != -1 and self._find_shortest_path(state, 1) != -1\n",
        "\n",
        "    def _get_possible_moves(self, state: GameState, player):\n",
        "        \"\"\"\n",
        "        Uses DFS to find valid moves (up to 2 steps, including jumps).\n",
        "        Returns a list of valid positions.\n",
        "        \"\"\"\n",
        "        board = state.game_board\n",
        "        current_pos = state.player_positions[player] * 2\n",
        "        valid_moves = []\n",
        "        stack = [(current_pos, 0)]\n",
        "        visited = np.zeros((2 * self.board_size - 1, 2 * self.board_size - 1), dtype=np.int8)\n",
        "        while stack:\n",
        "            pos, steps = stack.pop()\n",
        "            if pos[0] < 0 or pos[0] > 2 * self.board_size - 2 or pos[1] < 0 or pos[1] > 2 * self.board_size - 2:\n",
        "                continue\n",
        "            if board[*pos] == 1 or visited[*pos] == 1:\n",
        "                continue\n",
        "            if board[*pos] in [2, 3]:\n",
        "                steps = 0\n",
        "            visited[*pos] = 1\n",
        "            if steps == 2:\n",
        "                valid_moves.append(pos // 2)\n",
        "                continue\n",
        "            for direction in [[-1, 0], [1, 0], [0, -1], [0, 1]]:\n",
        "                stack.append((pos + direction, steps + 1))\n",
        "        return valid_moves\n",
        "\n",
        "    def is_move_valid(self, state: GameState, target_pos, player):\n",
        "        \"\"\"Checks if a move to target_pos is valid.\"\"\"\n",
        "        return any(np.array_equal(target_pos, move) for move in self._get_possible_moves(state, player))\n",
        "\n",
        "    def apply_action(self, state: GameState, action: tuple, player: int):\n",
        "        \"\"\"\n",
        "        Applies an action (move or wall placement) and returns the new state.\n",
        "        Returns None if the action is invalid.\n",
        "        \"\"\"\n",
        "        action_type, row, col = action\n",
        "        new_state = state.duplicate()\n",
        "        new_state.turn_count += 1\n",
        "        if action_type == 0:  # Move\n",
        "            if self.is_move_valid(new_state, (row, col), player):\n",
        "                new_state.game_board[*new_state.player_positions[player] * 2] = 0\n",
        "                new_state.game_board[row * 2, col * 2] = player + 2\n",
        "                new_state.player_positions[player] = (row, col)\n",
        "                return new_state\n",
        "            return None\n",
        "        else:  # Wall\n",
        "            if new_state.remaining_walls[player] == 0:\n",
        "                return None\n",
        "            orientation = action_type - 1\n",
        "            if new_state.wall_grid[orientation, row, col] != 0:\n",
        "                return None\n",
        "            new_state.wall_grid[orientation, row, col] = 1\n",
        "            new_state.wall_grid[1 - orientation, row, col] = -1\n",
        "            if orientation == 0 and col > 0:\n",
        "                new_state.wall_grid[0, row, col - 1] = -1\n",
        "            if orientation == 1 and row > 0:\n",
        "                new_state.wall_grid[1, row - 1, col] = -1\n",
        "            if orientation == 0 and col < self.board_size - 2:\n",
        "                new_state.wall_grid[0, row, col + 1] = -1\n",
        "            if orientation == 1 and row < self.board_size - 2:\n",
        "                new_state.wall_grid[1, row + 1, col] = -1\n",
        "            new_state.game_board[\n",
        "                row * 2 - orientation + 1 : row * 2 + orientation + 2,\n",
        "                col * 2 - (1 - orientation) + 1 : col * 2 + (1 - orientation) + 2\n",
        "            ] = 1\n",
        "            new_state.remaining_walls[player] -= 1\n",
        "            if not self.is_wall_valid(new_state):\n",
        "                return None\n",
        "            return new_state\n",
        "\n",
        "    def get_available_actions(self, state: GameState, player: int):\n",
        "        \"\"\"Returns a 3xNxN array of valid actions (moves and walls).\"\"\"\n",
        "        moves = self._get_possible_moves(state, player)\n",
        "        walls = [\n",
        "            (hv, r, c)\n",
        "            for hv in range(2)\n",
        "            for r in range(self.board_size - 1)\n",
        "            for c in range(self.board_size - 1)\n",
        "            if self.apply_action(state, (hv + 1, r, c), player) is not None\n",
        "        ]\n",
        "        actions = np.zeros((3, self.board_size, self.board_size))\n",
        "        for move in moves:\n",
        "            actions[0, *move] = 1\n",
        "        for hv, r, c in walls:\n",
        "            actions[1 + hv, r, c] = 1\n",
        "        return actions\n",
        "\n",
        "    def has_won(self, state: GameState, player):\n",
        "        \"\"\"Checks if the player has reached their goal row.\"\"\"\n",
        "        return state.player_positions[player][0] == (self.board_size - 1) * (1 - player)\n",
        "\n",
        "    def evaluate_draw(self, state: GameState, player: int):\n",
        "        \"\"\"\n",
        "        Returns a heuristic value based on the shortest path lengths.\n",
        "        Value = player's path length / (player's path length + opponent's path length).\n",
        "        \"\"\"\n",
        "        player_path = self._find_shortest_path(state, player)\n",
        "        opponent_path = self._find_shortest_path(state, 1 - player)\n",
        "        return player_path / (player_path + opponent_path)\n",
        "\n",
        "    def check_game_status(self, state: GameState, player: int):\n",
        "        \"\"\"\n",
        "        Returns (is_terminal, is_draw, value) for the game state.\n",
        "        Terminates after 50 moves or if a player wins.\n",
        "        \"\"\"\n",
        "        if state.turn_count > 50:\n",
        "            return True, True, self.evaluate_draw(state, player)\n",
        "        if self.has_won(state, player):\n",
        "            return True, False, 1\n",
        "        return False, False, 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Module 3: SearchNode and MCTSSearch\n",
        "Purpose: Implements the MCTS algorithm to select optimal moves.\n",
        "Key Features:\n",
        "- SearchNode: Represents a node in the MCTS tree, storing state, actions, and statistics.\n",
        "- MCTSSearch: Runs MCTS iterations to evaluate actions and return action probabilities.\n",
        "- Uses UCB formula for node selection.\n",
        "- Simulates random rollouts to estimate values.\n",
        "- Backpropagates results to update node statistics.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5Ur6qlG-08H2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YWdJmgAIqSMw"
      },
      "outputs": [],
      "source": [
        "class SearchNode:\n",
        "    def __init__(self, game: QuoridorGame, config, state: GameState, player, parent=None, action=None):\n",
        "        self.game = game\n",
        "        self.config = config\n",
        "        self.state = state\n",
        "        self.player = player\n",
        "        self.parent = parent\n",
        "        self.action = action\n",
        "        self.children = []\n",
        "        self.available_actions = self.game.get_available_actions(self.state, self.player)\n",
        "        self.visits = 0\n",
        "        self.value_sum = 0\n",
        "\n",
        "    def is_expanded(self):\n",
        "        \"\"\"Checks if all valid actions have been explored.\"\"\"\n",
        "        return np.sum(self.available_actions) == 0 and len(self.children) > 0\n",
        "\n",
        "    def choose_child(self):\n",
        "        \"\"\"Selects the child node with the highest UCB score.\"\"\"\n",
        "        best_score = -np.inf\n",
        "        best_child = None\n",
        "        for child in self.children:\n",
        "            score = self._calculate_ucb(child)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_child = child\n",
        "        return best_child\n",
        "\n",
        "    def _calculate_ucb(self, child):\n",
        "        \"\"\"Calculates the UCB score for a child node.\"\"\"\n",
        "        q_value = child.value_sum / child.visits\n",
        "        exploration = self.config['C'] * math.sqrt(math.log(self.visits) / child.visits)\n",
        "        return q_value + exploration\n",
        "\n",
        "    def expand_node(self):\n",
        "        \"\"\"Expands the node by selecting a random valid action and creating a child.\"\"\"\n",
        "        action = random.choice(list(zip(*np.where(self.available_actions == 1))))\n",
        "        self.available_actions[action] = 0\n",
        "        child_state = self.game.apply_action(self.state, action, self.player)\n",
        "        child = SearchNode(self.game, self.config, child_state, 1 - self.player, self, action)\n",
        "        self.children.append(child)\n",
        "        return child\n",
        "\n",
        "    def rollout(self):\n",
        "        \"\"\"Performs a random simulation from the current state until termination.\"\"\"\n",
        "        current_state = self.state.duplicate()\n",
        "        current_player = self.player\n",
        "        while True:\n",
        "            actions = self.game.get_available_actions(current_state, current_player)\n",
        "            action = random.choice(list(zip(*np.where(actions == 1))))\n",
        "            current_state = self.game.apply_action(current_state, action, current_player)\n",
        "            is_terminal, is_draw, value = self.game.check_game_status(current_state, current_player)\n",
        "            if is_terminal:\n",
        "                return is_draw, value\n",
        "            current_player = 1 - current_player\n",
        "\n",
        "    def propagate(self, value, is_draw):\n",
        "        \"\"\"Updates node statistics and propagates the value up the tree.\"\"\"\n",
        "        self.visits += 1\n",
        "        if is_draw:\n",
        "            self.value_sum += value * self.config['draw_discount']\n",
        "        else:\n",
        "            self.value_sum += value\n",
        "        if self.parent:\n",
        "            self.parent.propagate(1 - value, is_draw)\n",
        "\n",
        "class MCTSSearch:\n",
        "    def __init__(self, game: QuoridorGame, config):\n",
        "        self.game = game\n",
        "        self.config = config\n",
        "\n",
        "    def run_search(self, state, player):\n",
        "        \"\"\"Runs MCTS iterations and returns action probabilities.\"\"\"\n",
        "        root = SearchNode(self.game, self.config, state, player)\n",
        "        for _ in tqdm.trange(self.config['n_searches']):\n",
        "            node = root\n",
        "            while node.is_expanded():\n",
        "                node = node.choose_child()\n",
        "            is_terminal, is_draw, value = self.game.check_game_status(node.state, 1 - node.player)\n",
        "            if not is_terminal:\n",
        "                node = node.expand_node()\n",
        "                is_draw, value = node.rollout()\n",
        "                value = 1 - value\n",
        "            node.propagate(value, is_draw)\n",
        "        action_probs = np.zeros((3, self.game.board_size, self.game.board_size), dtype=np.float32)\n",
        "        for child in root.children:\n",
        "            q_value = child.value_sum / child.visits\n",
        "            visit_rate = child.visits / root.visits\n",
        "            action_probs[*child.action] = q_value + math.sqrt(visit_rate) * 0.1\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        return action_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8y0zdKwCqSMw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_policy(policy, valid_actions, state: QuoridorState, player):\n",
        "    if policy is None:\n",
        "        policy = np.zeros((3, state.N, state.N))\n",
        "    plt.figure(num=0)\n",
        "    plt.axis()\n",
        "    rect = plt.Rectangle((-0.5, -0.5), state.N, state.N, fc='w', ec='k')\n",
        "    plt.gca().add_patch(rect)\n",
        "\n",
        "    policy /= np.max(policy, axis=(0, 1, 2)) + 1e-8\n",
        "\n",
        "    for i in range(state.N):\n",
        "        for j in range(state.N):\n",
        "            rate = float(policy[0, i, j])\n",
        "            color = np.array([1-rate, 0, rate, 1]) if valid_actions[0, i, j] == 1 else 'w'\n",
        "            rect = plt.Rectangle((i-0.3, j-0.3), 0.6, 0.6, fc=color, ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "\n",
        "    for i in range(state.N - 1):\n",
        "        for j in range(state.N - 1):\n",
        "            rate = float(policy[1, i, j])\n",
        "            color = 'k' if state.walls[0, i, j] == 1 else ('w' if valid_actions[1, i, j] == 0 else np.array([1-rate, 0, rate, 1]))\n",
        "            rect = plt.Rectangle((i+0.5-0.1, j+0.5-0.5), 0.2, 1, fc=color, ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "\n",
        "            rate = float(policy[2, i, j])\n",
        "            color = 'k' if state.walls[1, i, j] == 1 else ('w' if valid_actions[2, i, j] == 0 else np.array([1-rate, 0, rate, 1]))\n",
        "            rect = plt.Rectangle((i+0.5-0.5, j+0.5-0.1), 1, 0.2, fc=color, ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "\n",
        "            rect = plt.Rectangle((i+0.5-0.1, j+0.5-0.1), 0.2, 0.2, fc='k', ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "\n",
        "\n",
        "\n",
        "    circle = plt.Circle((state.positions[0, 0], state.positions[0, 1]), 0.1, fc='g' if player == 0 else 'w', ec='k')\n",
        "    plt.gca().add_patch(circle)\n",
        "    circle = plt.Circle((state.positions[1, 0], state.positions[1, 1]), 0.1, fc='g' if player == 1 else 'k', ec='k')\n",
        "    plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dRWd8z7n0_1G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHQ3lmdS1ADV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Cwk_yOjvqSMw"
      },
      "outputs": [],
      "source": [
        "# Module 4: Visualization\n",
        "\"\"\"\n",
        "Module 4: VisualizePolicy\n",
        "Purpose: Visualizes the game board and policy probabilities for debugging and presentation.\n",
        "Key Features:\n",
        "- Displays the game board with player positions and walls.\n",
        "- Colors valid moves and walls based on policy probabilities.\n",
        "- Uses matplotlib to create a graphical representation.\n",
        "\"\"\"\n",
        "def visualize_policy(policy, valid_actions, state: GameState, player):\n",
        "    if policy is None:\n",
        "        policy = np.zeros((3, state.size, state.size))\n",
        "    plt.figure()\n",
        "    plt.axis()\n",
        "    rect = plt.Rectangle((-0.5, -0.5), state.size, state.size, fc='w', ec='k')\n",
        "    plt.gca().add_patch(rect)\n",
        "    policy = policy / (np.max(policy) + 1e-8)\n",
        "    for i in range(state.size):\n",
        "        for j in range(state.size):\n",
        "            intensity = float(policy[0, i, j])\n",
        "            color = np.array([1 - intensity, 0, intensity, 1]) if valid_actions[0, i, j] == 1 else 'w'\n",
        "            rect = plt.Rectangle((i - 0.3, j - 0.3), 0.6, 0.6, fc=color, ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "    for i in range(state.size - 1):\n",
        "        for j in range(state.size - 1):\n",
        "            intensity = float(policy[1, i, j])\n",
        "            color = 'k' if state.wall_grid[0, i, j] == 1 else ('w' if valid_actions[1, i, j] == 0 else np.array([1 - intensity, 0, intensity, 1]))\n",
        "            rect = plt.Rectangle((i + 0.5 - 0.1, j + 0.5 - 0.5), 0.2, 1, fc=color, ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "            intensity = float(policy[2, i, j])\n",
        "            color = 'k' if state.wall_grid[1, i, j] == 1 else ('w' if valid_actions[2, i, j] == 0 else np.array([1 - intensity, 0, intensity, 1]))\n",
        "            rect = plt.Rectangle((i + 0.5 - 0.5, j + 0.5 - 0.1), 1, 0.2, fc=color, ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "            rect = plt.Rectangle((i + 0.5 - 0.1, j + 0.5 - 0.1), 0.2, 0.2, fc='k', ec='k')\n",
        "            plt.gca().add_patch(rect)\n",
        "    circle = plt.Circle((state.player_positions[0, 0], state.player_positions[0, 1]), 0.1, fc='g' if player == 0 else 'w', ec='k')\n",
        "    plt.gca().add_patch(circle)\n",
        "    circle = plt.Circle((state.player_positions[1, 0], state.player_positions[1, 1]), 0.1, fc='g' if player == 1 else 'k', ec='k')\n",
        "    plt.gca().add_patch(circle)\n",
        "    plt.axis('scaled')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 5: Main Game Loop\n",
        "\"\"\"\n",
        "Module 5: Main Game Loop\n",
        "Purpose: Runs the Quoridor game with an MCTS-based AI opponent.\n",
        "Key Features:\n",
        "- Initializes the game with a specified board size and number of walls.\n",
        "- Alternates between AI moves (using MCTS) and player input (for testing).\n",
        "- Visualizes the game state and policy after each move.\n",
        "- Terminates when a player wins or the game reaches 50 moves.\n",
        "\"\"\"\n",
        "def main():\n",
        "    game = QuoridorGame(board_size=5, total_walls=3)\n",
        "    config = {\n",
        "        'draw_discount': 0.0,\n",
        "        'C': 2,\n",
        "        'n_searches': 500,\n",
        "    }\n",
        "    mcts = MCTSSearch(game, config)\n",
        "    state = game.new_game()\n",
        "    current_player = 0\n",
        "    empty_policy = np.zeros((3, game.board_size, game.board_size))\n",
        "    visualize_policy(empty_policy, empty_policy, state, current_player)\n",
        "    while True:\n",
        "        policy = mcts.run_search(state, current_player)\n",
        "        action = np.unravel_index(np.argmax(policy), policy.shape)\n",
        "        action_type, row, col = action\n",
        "        new_state = game.apply_action(state, (action_type, row, col), current_player)\n",
        "        visualize_policy(policy, game.get_available_actions(state, current_player), new_state, current_player)\n",
        "        state = new_state\n",
        "        is_terminal, _, value = game.check_game_status(state, current_player)\n",
        "        if is_terminal:\n",
        "            print(f\"Game over: Player {current_player} {'wins' if value == 1 else 'draws'}\")\n",
        "            break\n",
        "        current_player = 1 - current_player\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Y4bE8cC11FAt",
        "outputId": "be5c0cd7-2dc0-412e-efce-0681ad14aee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 498/500 [00:53<00:00, 13.56it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt-SIrviqSMw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}