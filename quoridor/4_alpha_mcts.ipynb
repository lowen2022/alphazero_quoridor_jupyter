{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import heapq\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Module 1: Quoridor Game Logic\n",
        "# ---------------------------------------------\n",
        "class QuoridorGame:\n",
        "    \"\"\"Manages the Quoridor game rules and state transitions.\"\"\"\n",
        "\n",
        "    def __init__(self, board_size=9, wall_count=10):\n",
        "        self.board_size = board_size\n",
        "        self.wall_count = wall_count\n",
        "\n",
        "    def find_shortest_path(self, state, player):\n",
        "        \"\"\"Use A* algorithm to find the shortest path to the goal for a player.\"\"\"\n",
        "        board = state.board\n",
        "        start = tuple(state.player_positions[player] * 2)  # Convert to tuple for heap\n",
        "        queue = [(0, 0, start)]  # (f_score, g_score, position_tuple)\n",
        "        visited = np.zeros((2 * self.board_size - 1, 2 * self.board_size - 1), dtype=np.int8)\n",
        "        target_row = (2 * self.board_size - 2) * (1 - player)  # Goal row for player\n",
        "\n",
        "        while queue:\n",
        "            _, g, pos = heapq.heappop(queue)\n",
        "            pos = np.array(pos)  # Convert back to NumPy array for indexing\n",
        "            if pos[0] < 0 or pos[0] >= 2 * self.board_size - 1 or pos[1] < 0 or pos[1] >= 2 * self.board_size - 1:\n",
        "                continue\n",
        "            if board[tuple(pos)] == 1 or visited[tuple(pos)]:\n",
        "                continue\n",
        "            if pos[0] == target_row:\n",
        "                return g\n",
        "            visited[tuple(pos)] = 1\n",
        "            for direction in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
        "                new_pos = pos + np.array(direction)\n",
        "                h = abs(target_row - new_pos[0])  # Manhattan distance heuristic\n",
        "                heapq.heappush(queue, (g + 1 + h, g + 1, tuple(new_pos)))  # Store as tuple\n",
        "        return -1\n",
        "\n",
        "    # ... (rest of the QuoridorGame class remains unchanged, include from original code)\n",
        "\n",
        "    def create_initial_state(self):\n",
        "        return GameState(self.board_size, self.wall_count)\n",
        "\n",
        "    def is_wall_placement_valid(self, state):\n",
        "        return self.find_shortest_path(state, 0) != -1 and self.find_shortest_path(state, 1) != -1\n",
        "\n",
        "    def get_valid_moves(self, state, player):\n",
        "        board = state.board\n",
        "        current_pos = state.player_positions[player] * 2\n",
        "        valid_moves = []\n",
        "        stack = [(current_pos, 0)]\n",
        "        visited = np.zeros((2 * self.board_size - 1, 2 * self.board_size - 1), dtype=np.int8)\n",
        "\n",
        "        while stack:\n",
        "            pos, steps = stack.pop()\n",
        "            if pos[0] < 0 or pos[0] > 2 * self.board_size - 2 or pos[1] < 0 or pos[1] > 2 * self.board_size - 2:\n",
        "                continue\n",
        "            if board[*pos] == 1 or visited[*pos]:\n",
        "                continue\n",
        "            if board[*pos] in (2, 3):\n",
        "                steps = 0\n",
        "            visited[*pos] = 1\n",
        "            if steps == 2:\n",
        "                valid_moves.append(pos // 2)\n",
        "                continue\n",
        "            for direction in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
        "                stack.append((pos + np.array(direction), steps + 1))\n",
        "        return valid_moves\n",
        "\n",
        "    def is_move_valid(self, state, next_pos, player):\n",
        "        return any(np.array_equal(next_pos, move) for move in self.get_valid_moves(state, player))\n",
        "\n",
        "    def apply_action(self, state, action, player):\n",
        "        action_type, value = action\n",
        "        new_state = state.copy()\n",
        "        if action_type == 0:\n",
        "            if self.is_move_valid(new_state, value, player):\n",
        "                new_state.board[*new_state.player_positions[player] * 2] = 0\n",
        "                new_state.board[*np.array(value) * 2] = player + 2\n",
        "                new_state.player_positions[player] = value\n",
        "                return new_state\n",
        "            return None\n",
        "        else:\n",
        "            if new_state.walls_left[player] == 0:\n",
        "                return None\n",
        "            orientation = action_type - 1\n",
        "            row, col = value\n",
        "            if new_state.wall_grid[orientation, row, col] != 0:\n",
        "                return None\n",
        "            new_state.wall_grid[orientation, row, col] = 1\n",
        "            new_state.wall_grid[1 - orientation, row, col] = -1\n",
        "            if orientation == 0 and col > 0:\n",
        "                new_state.wall_grid[0, row, col - 1] = -1\n",
        "            if orientation == 1 and row > 0:\n",
        "                new_state.wall_grid[1, row - 1, col] = -1\n",
        "            if orientation == 0 and col < self.board_size - 2:\n",
        "                new_state.wall_grid[0, row, col + 1] = -1\n",
        "            if orientation == 1 and row < self.board_size - 2:\n",
        "                new_state.wall_grid[1, row + 1, col] = -1\n",
        "            new_state.board[\n",
        "                row * 2 - orientation + 1 : row * 2 + orientation + 2,\n",
        "                col * 2 - (1 - orientation) + 1 : col * 2 + (1 - orientation) + 2\n",
        "            ] = 1\n",
        "            new_state.walls_left[player] -= 1\n",
        "            if not self.is_wall_placement_valid(new_state):\n",
        "                return None\n",
        "            return new_state\n",
        "\n",
        "    def get_possible_actions(self, state, player):\n",
        "        moves = self.get_valid_moves(state, player)\n",
        "        walls = [\n",
        "            (hv, (r, c))\n",
        "            for hv in range(2)\n",
        "            for r in range(self.board_size - 1)\n",
        "            for c in range(self.board_size - 1)\n",
        "            if self.apply_action(state, (hv + 1, (r, c)), player) is not None\n",
        "        ]\n",
        "        action_tensor = np.zeros((3, self.board_size, self.board_size), dtype=np.float32)\n",
        "        for move in moves:\n",
        "            action_tensor[0, *move] = 1\n",
        "        for hv, (r, c) in walls:\n",
        "            action_tensor[1 + hv, r, c] = 1\n",
        "        return action_tensor\n",
        "\n",
        "    def has_won(self, state, player):\n",
        "        return state.player_positions[player][0] == (self.board_size - 1) * (1 - player)\n",
        "\n",
        "    def evaluate_state(self, state, player):\n",
        "        player_dist = self.find_shortest_path(state, player)\n",
        "        opponent_dist = self.find_shortest_path(state, 1 - player)\n",
        "        return player_dist / (player_dist + opponent_dist + 1e-8)\n",
        "\n",
        "    def check_game_status(self, state, player, turns):\n",
        "        if turns > 50:\n",
        "            return True, True, self.evaluate_state(state, player)\n",
        "        if self.has_won(state, player):\n",
        "            return True, False, 1.0\n",
        "        return False, False, 0.0\n",
        "\n",
        "class GameState:\n",
        "    def __init__(self, size, walls, copy=None):\n",
        "        self.size = size\n",
        "        if copy:\n",
        "            self.player_positions = copy.player_positions.copy()\n",
        "            self.walls_left = copy.walls_left.copy()\n",
        "            self.wall_grid = copy.wall_grid.copy()\n",
        "            self.board = copy.board.copy()\n",
        "        else:\n",
        "            self.player_positions = np.array([[0, size // 2], [size - 1, size // 2]])\n",
        "            self.walls_left = np.array([walls, walls])\n",
        "            self.wall_grid = np.zeros((2, size - 1, size - 1), dtype=np.int8)\n",
        "            self.board = self.initialize_board()\n",
        "\n",
        "    def initialize_board(self):\n",
        "        board = np.zeros((2 * self.size - 1, 2 * self.size - 1), dtype=np.int8)\n",
        "        board[1::2, 1::2] = 1\n",
        "        board[self.player_positions[0, 0] * 2, self.player_positions[0, 1] * 2] = 2\n",
        "        board[self.player_positions[1, 0] * 2, self.player_positions[1, 1] * 2] = 3\n",
        "        return board\n",
        "\n",
        "    def copy(self):\n",
        "        return GameState(self.size, 0, copy=self)\n",
        "\n",
        "    def encode_state(self, player):\n",
        "        encoded = np.zeros((4, self.size, self.size), dtype=np.float32)\n",
        "        encoded[player, self.player_positions[0, 0], self.player_positions[0, 1]] = 1\n",
        "        encoded[1 - player, self.player_positions[1, 0], self.player_positions[1, 1]] = 1\n",
        "        encoded[2, :, :] = np.pad(self.wall_grid[0] == 1, ((0, 1), (0, 1)), mode='constant')\n",
        "        encoded[3, :, :] = np.pad(self.wall_grid[1] == 1, ((0, 1), (0, 1)), mode='constant')\n",
        "        return encoded\n"
      ],
      "metadata": {
        "id": "HMt2Ucsl3vgg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------------\n",
        "# Module 2: Neural Network for AlphaZero\n",
        "# ---------------------------------------------\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        return F.relu(x)\n",
        "\n",
        "class GameNetwork(nn.Module):\n",
        "    def __init__(self, game, num_blocks, channels):\n",
        "        super().__init__()\n",
        "        self.game = game\n",
        "        self.initial_conv = nn.Sequential(\n",
        "            nn.Conv2d(4, channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            OrderedDict([(f'res_block_{i}', ResidualBlock(channels)) for i in range(num_blocks)])\n",
        "        )\n",
        "        self.policy_output = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels, 3, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.value_output = nn.Sequential(\n",
        "            nn.Conv2d(channels, 3, kernel_size=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * game.board_size * game.board_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.res_blocks(x)\n",
        "        policy = self.policy_output(x)\n",
        "        value = self.value_output(x)\n",
        "        return policy, value\n"
      ],
      "metadata": {
        "id": "RaR-xzCt4RF5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------------\n",
        "# Module 3: Monte Carlo Tree Search (MCTS)\n",
        "# ---------------------------------------------\n",
        "class TreeNode:\n",
        "    def __init__(self, game, params, state, player, turn, parent=None, action=None):\n",
        "        self.game = game\n",
        "        self.params = params\n",
        "        self.state = state\n",
        "        self.player = player\n",
        "        self.turn = turn\n",
        "        self.parent = parent\n",
        "        self.action = action\n",
        "        self.children = []\n",
        "        self.valid_actions = game.get_possible_actions(state, player)\n",
        "        self.visits = 0\n",
        "        self.value_sum = 0\n",
        "\n",
        "    def is_expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def select_child(self):\n",
        "        best_score = -np.inf\n",
        "        best_child = None\n",
        "        for child in self.children:\n",
        "            score = self.compute_ucb(child)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_child = child\n",
        "        return best_child\n",
        "\n",
        "    def compute_ucb(self, child):\n",
        "        q = child.value_sum / (child.visits + 1e-8)\n",
        "        exploration = self.params['C'] * np.sqrt(np.log(self.visits + 1) / (child.visits + 1e-8))\n",
        "        return q + exploration\n",
        "\n",
        "    def expand_node(self, valid_actions, policy):\n",
        "        for idx in zip(*np.where(valid_actions == 1)):\n",
        "            if policy[*idx] > 0:\n",
        "                action_type, row, col = idx\n",
        "                new_state = self.game.apply_action(self.state, (action_type, (row, col)), 1 - self.player)\n",
        "                if new_state:\n",
        "                    child = TreeNode(self.game, self.params, new_state, 1 - self.player, self.turn + 1, self, idx)\n",
        "                    self.children.append(child)\n",
        "\n",
        "    def backprop(self, value, is_draw):\n",
        "        self.visits += 1\n",
        "        self.value_sum += value * self.params['draw_discount'] if is_draw else value\n",
        "        if self.parent:\n",
        "            self.parent.backprop(value, is_draw)\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, game, params, network):\n",
        "        self.game = game\n",
        "        self.params = params\n",
        "        self.network = network\n",
        "\n",
        "    def run_search(self, state, player):\n",
        "        root = TreeNode(self.game, self.params, state, 1 - player, 0)\n",
        "        for _ in tqdm(range(self.params['n_searches'])):\n",
        "            node = root\n",
        "            while node.is_expanded():\n",
        "                node = node.select_child()\n",
        "            is_terminal, is_draw, value = self.game.check_game_status(node.state, 1 - node.player, node.turn)\n",
        "            if not is_terminal:\n",
        "                policy, value = self.network(torch.tensor(node.state.encode_state(1 - node.player)).unsqueeze(0))\n",
        "                policy = torch.softmax(policy.flatten(1), dim=1).reshape(3, self.game.board_size, self.game.board_size).detach().numpy()\n",
        "                valid_actions = self.game.get_possible_actions(node.state, 1 - node.player)\n",
        "                policy *= valid_actions\n",
        "                policy /= np.sum(policy) + 1e-8\n",
        "                value = value.item()\n",
        "                node.expand_node(valid_actions, policy)\n",
        "            node.backprop(value, is_draw)\n",
        "        action_probs = np.zeros((3, self.game.board_size, self.game.board_size), dtype=np.float32)\n",
        "        for child in root.children:\n",
        "            action_probs[*child.action] = child.value_sum / (child.visits + 1e-8)\n",
        "        action_probs /= np.sum(action_probs) + 1e-8\n",
        "        return action_probs\n"
      ],
      "metadata": {
        "id": "2mek_PrB4V1y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------------\n",
        "# Module 4: Visualization\n",
        "# ---------------------------------------------\n",
        "def visualize_board(policy, state, player):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.axis('equal')\n",
        "    plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), state.size, state.size, fc='w', ec='k'))\n",
        "\n",
        "    for i in range(state.size):\n",
        "        for j in range(state.size):\n",
        "            prob = policy[0, i, j] if policy is not None else 0\n",
        "            color = np.array([1 - prob, 0, prob, 1]) if prob > 0 else 'w'\n",
        "            plt.gca().add_patch(plt.Rectangle((i - 0.3, j - 0.3), 0.6, 0.6, fc=color, ec='k'))\n",
        "\n",
        "    for i in range(state.size - 1):\n",
        "        for j in range(state.size - 1):\n",
        "            h_prob = policy[1, i, j] if policy is not None else 0\n",
        "            v_prob = policy[2, i, j] if policy is not None else 0\n",
        "            h_color = np.array([1 - h_prob, 0, h_prob, 1]) if state.wall_grid[0, i, j] != 1 else 'k'\n",
        "            v_color = np.array([1 - v_prob, 0, v_prob, 1]) if state.wall_grid[1, i, j] != 1 else 'k'\n",
        "            plt.gca().add_patch(plt.Rectangle((i + 0.4, j - 0.5), 0.2, 1, fc=h_color, ec='k'))\n",
        "            plt.gca().add_patch(plt.Rectangle((i - 0.5, j + 0.4), 1, 0.2, fc=v_color, ec='k'))\n",
        "            plt.gca().add_patch(plt.Rectangle((i + 0.4, j + 0.4), 0.2, 0.2, fc='k', ec='k'))\n",
        "\n",
        "    plt.gca().add_patch(plt.Circle((state.player_positions[0, 0], state.player_positions[0, 1]), 0.1, fc='g' if player == 0 else 'w', ec='k'))\n",
        "    plt.gca().add_patch(plt.Circle((state.player_positions[1, 0], state.player_positions[1, 1]), 0.1, fc='g' if player == 1 else 'k', ec='k'))\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "GrVFkrNg4YAB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------------\n",
        "# Module 5: AlphaZero Training\n",
        "# ---------------------------------------------\n",
        "class AlphaZeroTrainer:\n",
        "    def __init__(self, network, optimizer, game, params):\n",
        "        self.network = network\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.params = params\n",
        "        self.mcts = MCTS(game, params, network)\n",
        "\n",
        "    def run_self_play(self):\n",
        "        history = []\n",
        "        player = 1\n",
        "        state = self.game.create_initial_state()\n",
        "        turn = 0\n",
        "        while True:\n",
        "            action_probs = self.mcts.run_search(state, player)\n",
        "            history.append((state, action_probs, player))\n",
        "            action_idx = np.unravel_index(np.argmax(action_probs), action_probs.shape)\n",
        "            action_type, row, col = action_idx\n",
        "            state = self.game.apply_action(state, (action_type, (row, col)), player)\n",
        "            is_terminal, is_draw, value = self.game.check_game_status(state, player, turn)\n",
        "            turn += 1\n",
        "            if is_terminal:\n",
        "                training_data = []\n",
        "                for hist_state, hist_probs, hist_player in history:\n",
        "                    outcome = value if hist_player == player else 1 - value\n",
        "                    training_data.append((hist_state.encode_state(hist_player), hist_probs, outcome))\n",
        "                return training_data\n",
        "            player = 1 - player\n",
        "\n",
        "    def train_network(self, data):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        for iteration in range(self.params['n_iterations']):\n",
        "            data_buffer = []\n",
        "            self.network.eval()\n",
        "            for _ in range(self.params['n_selfplay_iterations']):\n",
        "                data_buffer.extend(self.run_self_play())\n",
        "            self.network.train()\n",
        "            for _ in range(self.params['n_epochs']):\n",
        "                self.train_network(data_buffer)\n",
        "            torch.save(self.network.state_dict(), f'model_iter_{iteration}.pt')\n",
        "            torch.save(self.optimizer.state_dict(), f'optimizer_iter_{iteration}.pt')\n"
      ],
      "metadata": {
        "id": "GpMJ7lHQ4ZaJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------------\n",
        "# Main Execution\n",
        "# ---------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    game = QuoridorGame(board_size=5, wall_count=6)\n",
        "    network = GameNetwork(game, num_blocks=3, channels=3)\n",
        "    optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
        "    params = {\n",
        "        'C': 2.0,\n",
        "        'n_searches': 10,\n",
        "        'n_iterations': 3,\n",
        "        'n_selfplay_iterations': 10,\n",
        "        'n_epochs': 100,\n",
        "        'draw_discount': 0.2\n",
        "    }\n",
        "\n",
        "    trainer = AlphaZeroTrainer(network, optimizer, game, params)\n",
        "    trainer.train()"
      ],
      "metadata": {
        "id": "1J763K-Y4aN5",
        "outputId": "34b1d125-b3ab-44c6-d01b-942fda740b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 74.02it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 185.34it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 451.61it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 484.08it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 518.17it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 996.51it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1129.96it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 999.05it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 80.01it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 188.70it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 370.20it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 515.17it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 544.92it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 999.69it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1103.44it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1075.57it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 81.09it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 185.30it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 411.12it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 509.09it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 518.19it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 986.99it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1020.44it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1009.02it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 82.52it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 196.24it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 450.24it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 428.39it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 360.57it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1142.58it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1156.86it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1131.18it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 82.37it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 189.42it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 418.37it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 496.78it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 571.98it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1082.82it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1025.13it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 909.77it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 78.36it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 198.35it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 397.84it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 241.08it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 313.35it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 734.82it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1088.16it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1196.36it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 79.29it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 195.93it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 441.75it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 510.46it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 511.66it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 994.78it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1126.86it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 889.55it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 72.59it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 199.81it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 471.33it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 508.67it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 557.63it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1012.26it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1075.30it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1094.32it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 81.34it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 173.20it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 451.45it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 518.86it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 504.03it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 984.14it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1020.88it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 984.23it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 66.03it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 64.12it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 200.96it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 168.29it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 208.36it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 658.21it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 615.86it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 721.69it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 111.21it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 206.70it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 189.38it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 142.31it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 650.23it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 374.85it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 609.06it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 37.25it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 81.51it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 114.20it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 57.44it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 76.16it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 447.38it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 931.10it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 649.74it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 51.62it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 132.06it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 311.66it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 325.12it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 337.40it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 686.88it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 741.70it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 742.14it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 44.30it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 107.95it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 240.37it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 304.97it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 316.21it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 588.67it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 738.07it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 661.86it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 48.99it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 190.43it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 455.50it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 481.91it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 520.42it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 736.46it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1074.58it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1126.96it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 72.59it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 190.33it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 446.40it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 514.58it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 538.64it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1035.81it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1203.67it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1008.78it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 78.35it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 185.98it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 439.86it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 517.07it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 551.25it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 921.40it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 929.86it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 878.77it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 78.27it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 185.71it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 437.71it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 506.94it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 532.25it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1032.98it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1087.11it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1137.99it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 78.96it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 142.06it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 440.63it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 453.95it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 539.09it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1084.16it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1126.96it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1072.27it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 82.27it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 183.62it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 448.02it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 463.30it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 543.64it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 920.85it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1027.76it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1059.46it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 76.61it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 192.06it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 447.00it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 501.17it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 585.71it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 985.94it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1042.87it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1080.48it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 80.48it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 195.08it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 429.18it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 494.28it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 538.62it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 994.52it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 709.64it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 619.31it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 77.80it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 197.46it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 449.66it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 472.27it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 560.29it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 942.99it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 914.95it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 966.61it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 74.85it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 191.36it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 414.35it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 465.70it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 555.04it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1016.26it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 840.91it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1091.70it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 78.70it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 189.08it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 394.59it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 462.56it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 534.33it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 982.69it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1086.13it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1036.58it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 69.67it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 189.39it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 470.81it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 498.66it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 551.95it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1007.57it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 917.17it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1100.20it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 79.07it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 192.92it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 395.58it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 410.17it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 532.09it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 933.25it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1094.20it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 979.61it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 75.69it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 186.47it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 432.38it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 508.18it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 466.33it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 938.89it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 970.19it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1084.25it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 79.92it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 147.64it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 409.24it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 452.08it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 529.06it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 994.17it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1045.07it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1045.54it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 77.29it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 192.13it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 429.13it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 458.16it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 515.98it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 803.28it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1045.91it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 1072.33it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}