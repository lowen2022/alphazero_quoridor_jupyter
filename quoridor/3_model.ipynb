{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oclnr3E81OOF",
        "outputId": "e7f538c7-9658-4cb6-9f11-9527321b7763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted value: tensor([[0.4281]], grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import heapq\n",
        "import itertools\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Module 1: GameBoardState\n",
        "# Description: Manages the state of the Quoridor game board, including player positions, walls, and board representation.\n",
        "# Purpose: Provides a container for the game state, allowing initialization, copying, and encoding for neural network input.\n",
        "class GameBoardState:\n",
        "    \"\"\"\n",
        "    Represents the state of a Quoridor game board.\n",
        "\n",
        "    Attributes:\n",
        "        board_size (int): Size of the board (default 9x9).\n",
        "        player_locations (numpy array): 2x2 array of player positions [row, col] for players 0 and 1.\n",
        "        remaining_walls (numpy array): Number of walls left for each player.\n",
        "        wall_grid (numpy array): 2x(N-1)x(N-1) array for horizontal and vertical walls.\n",
        "        game_board (numpy array): (2N-1)x(2N-1) array representing the board with players and walls.\n",
        "    \"\"\"\n",
        "    def __init__(self, size=9, wall_count=10, copy_from=None):\n",
        "        self.board_size = size\n",
        "        if copy_from:\n",
        "            self.board_size = copy_from.board_size\n",
        "            self.player_locations = copy_from.player_locations.copy()\n",
        "            self.remaining_walls = copy_from.remaining_walls.copy()\n",
        "            self.wall_grid = copy_from.wall_grid.copy()\n",
        "            self.game_board = copy_from.game_board.copy()\n",
        "        else:\n",
        "            self.player_locations = np.array([[0, size // 2], [size - 1, size // 2]])\n",
        "            self.remaining_walls = np.array([wall_count, wall_count])\n",
        "            self.wall_grid = np.zeros((2, size - 1, size - 1), dtype=np.int8)\n",
        "            self.game_board = self._initialize_board()\n",
        "\n",
        "    def _initialize_board(self):\n",
        "        \"\"\"\n",
        "        Creates the initial game board representation.\n",
        "\n",
        "        Returns:\n",
        "            numpy array: (2N-1)x(2N-1) board with intersections marked and players positioned.\n",
        "        \"\"\"\n",
        "        board = np.zeros((2 * self.board_size - 1, 2 * self.board_size - 1), dtype=np.int8)\n",
        "        board[1::2, 1::2] = 1  # Mark intersections\n",
        "        board[self.player_locations[0, 0] * 2, self.player_locations[0, 1] * 2] = 2  # Player 0\n",
        "        board[self.player_locations[1, 0] * 2, self.player_locations[1, 1] * 2] = 3  # Player 1\n",
        "        return board\n",
        "\n",
        "    def duplicate(self):\n",
        "        \"\"\"\n",
        "        Creates a deep copy of the current state.\n",
        "\n",
        "        Returns:\n",
        "            GameBoardState: A new instance with identical state.\n",
        "        \"\"\"\n",
        "        return GameBoardState(copy_from=self)\n",
        "\n",
        "    def encode_state(self, player):\n",
        "        \"\"\"\n",
        "        Encodes the game state into a 4-channel tensor for neural network input.\n",
        "\n",
        "        Args:\n",
        "            player (int): Perspective player (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            numpy array: 4xNxN array with player positions and wall placements.\n",
        "        \"\"\"\n",
        "        encoded = np.zeros((4, self.board_size, self.board_size), dtype=np.float32)\n",
        "        encoded[player, self.player_locations[0, 0], self.player_locations[0, 1]] = 1\n",
        "        encoded[1 - player, self.player_locations[1, 0], self.player_locations[1, 1]] = 1\n",
        "        encoded[2, :, :] = np.pad(self.wall_grid[0, :, :] == 1, ((0, 1), (0, 1)), mode='constant')\n",
        "        encoded[3, :, :] = np.pad(self.wall_grid[1, :, :] == 1, ((0, 1), (0, 1)), mode='constant')\n",
        "        return encoded\n",
        "\n",
        "# Module 2: QuoridorGame\n",
        "# Description: Implements the rules and logic of the Quoridor game.\n",
        "# Purpose: Manages game mechanics such as valid moves, wall placements, win conditions, and state transitions.\n",
        "class QuoridorGame:\n",
        "    \"\"\"\n",
        "    Manages the rules and logic for the Quoridor game.\n",
        "\n",
        "    Attributes:\n",
        "        size (int): Board size (NxN).\n",
        "        wall_limit (int): Number of walls per player.\n",
        "    \"\"\"\n",
        "    def __init__(self, size, wall_limit):\n",
        "        self.size = size\n",
        "        self.wall_limit = wall_limit\n",
        "\n",
        "    def create_initial_state(self):\n",
        "        \"\"\"\n",
        "        Initializes a new game state.\n",
        "\n",
        "        Returns:\n",
        "            GameBoardState: Starting state of the game.\n",
        "        \"\"\"\n",
        "        return GameBoardState(self.size, self.wall_limit)\n",
        "\n",
        "    def _find_shortest_path(self, state, player):\n",
        "        \"\"\"\n",
        "        Uses A* algorithm to find the shortest path to the goal for a player.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            player (int): Player index (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            int: Length of shortest path or -1 if no path exists.\n",
        "        \"\"\"\n",
        "        board = state.game_board\n",
        "        start = state.player_locations[player] * 2\n",
        "        priority_queue = []\n",
        "        heuristic = lambda pos: (2 * self.size - 2 - pos[0]) * (1 - player) + (2 * pos[0]) * player\n",
        "        heapq.heappush(priority_queue, (-heuristic(start), 0, -1, start))\n",
        "        visited = np.zeros((2 * self.size - 1, 2 * self.size - 1), dtype=np.int8)\n",
        "        for step in itertools.count():\n",
        "            if not priority_queue:\n",
        "                return -1\n",
        "            _, steps, _, pos = heapq.heappop(priority_queue)\n",
        "            if pos[0] < 0 or pos[0] > 2 * self.size - 2 or pos[1] < 0 or pos[1] > 2 * self.size - 2:\n",
        "                continue\n",
        "            if board[*pos] == 1 or visited[*pos] == 1:\n",
        "                continue\n",
        "            if pos[0] == (2 * self.size - 2) * (1 - player):\n",
        "                return steps\n",
        "            visited[*pos] = 1\n",
        "            directions = np.array([[-1, 0], [1, 0], [0, -1], [0, 1]])\n",
        "            for i, direction in enumerate(directions):\n",
        "                next_pos = pos + direction\n",
        "                heapq.heappush(priority_queue, (-(heuristic(next_pos) + steps + 1), steps + 1, 4 * step + i, next_pos))\n",
        "\n",
        "    def is_wall_placement_valid(self, state):\n",
        "        \"\"\"\n",
        "        Checks if the current wall configuration allows a path to the goal for both players.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if paths exist, False otherwise.\n",
        "        \"\"\"\n",
        "        return all(self._find_shortest_path(state, i) != -1 for i in range(2))\n",
        "\n",
        "    def _find_possible_moves(self, state, player):\n",
        "        \"\"\"\n",
        "        Uses DFS to find valid moves for a player, including jumps.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            player (int): Player index (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            list: List of valid move positions.\n",
        "        \"\"\"\n",
        "        board = state.game_board\n",
        "        current_pos = state.player_locations[player] * 2\n",
        "        possible_moves = []\n",
        "        stack = [(current_pos, 0)]\n",
        "        visited = np.zeros((2 * self.size - 1, 2 * self.size - 1), dtype=np.int8)\n",
        "        while stack:\n",
        "            pos, steps = stack.pop()\n",
        "            if pos[0] < 0 or pos[0] > 2 * self.size - 2 or pos[1] < 0 or pos[1] > 2 * self.size - 2:\n",
        "                continue\n",
        "            if board[*pos] == 1 or visited[*pos] == 1:\n",
        "                continue\n",
        "            if board[*pos] in [2, 3]:\n",
        "                steps = 0\n",
        "            visited[*pos] = 1\n",
        "            if steps == 2:\n",
        "                possible_moves.append(pos // 2)\n",
        "                continue\n",
        "            for direction in np.array([[-1, 0], [1, 0], [0, -1], [0, 1]]):\n",
        "                stack.append((pos + direction, steps + 1))\n",
        "        return possible_moves\n",
        "\n",
        "    def is_move_valid(self, state, target_pos, player):\n",
        "        \"\"\"\n",
        "        Checks if a move is valid for the player.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            target_pos (tuple): Target position (row, col).\n",
        "            player (int): Player index (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the move is valid, False otherwise.\n",
        "        \"\"\"\n",
        "        target = np.array(target_pos)\n",
        "        return any(np.array_equal(target, move) for move in self._find_possible_moves(state, player))\n",
        "\n",
        "    def apply_action(self, state, action, player):\n",
        "        \"\"\"\n",
        "        Applies an action (move or wall placement) to the state.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            action (tuple): Action type (0 for move, 1 for horizontal wall, 2 for vertical wall) and value.\n",
        "            player (int): Player index (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            GameBoardState or None: New state if action is valid, None otherwise.\n",
        "        \"\"\"\n",
        "        action_type, action_value = action\n",
        "        new_state = state.duplicate()\n",
        "        if action_type == 0:\n",
        "            if self.is_move_valid(new_state, action_value, player):\n",
        "                new_state.game_board[*new_state.player_locations[player] * 2] = 0\n",
        "                new_state.game_board[*np.array(action_value) * 2] = player + 2\n",
        "                new_state.player_locations[player] = action_value\n",
        "                return new_state\n",
        "            return None\n",
        "        else:\n",
        "            if new_state.remaining_walls[player] == 0:\n",
        "                return None\n",
        "            orientation = action_type - 1\n",
        "            row, col = action_value\n",
        "            if new_state.wall_grid[orientation, row, col] != 0:\n",
        "                return None\n",
        "            new_state.wall_grid[orientation, row, col] = 1\n",
        "            new_state.wall_grid[1 - orientation, row, col] = -1\n",
        "            if orientation == 0 and col > 0:\n",
        "                new_state.wall_grid[0, row, col - 1] = -1\n",
        "            if orientation == 1 and row > 0:\n",
        "                new_state.wall_grid[1, row - 1, col] = -1\n",
        "            if orientation == 0 and col < self.size - 2:\n",
        "                new_state.wall_grid[0, row, col + 1] = -1\n",
        "            if orientation == 1 and row < self.size - 2:\n",
        "                new_state.wall_grid[1, row + 1, col] = -1\n",
        "            new_state.game_board[\n",
        "                row * 2 - orientation + 1: row * 2 + orientation + 2,\n",
        "                col * 2 - (1 - orientation) + 1: col * 2 + (1 - orientation) + 2\n",
        "            ] = 1\n",
        "            new_state.remaining_walls[player] -= 1\n",
        "            if not self.is_wall_placement_valid(new_state):\n",
        "                return None\n",
        "            return new_state\n",
        "\n",
        "    def get_available_actions(self, state, player):\n",
        "        \"\"\"\n",
        "        Retrieves all valid actions for a player.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            player (int): Player index (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            list: List of valid actions (moves and wall placements).\n",
        "        \"\"\"\n",
        "        moves = [(0, tuple(move)) for move in self._find_possible_moves(state, player)]\n",
        "        walls = [\n",
        "            (1 + orient, (row, col))\n",
        "            for orient in range(2)\n",
        "            for row in range(self.size - 1)\n",
        "            for col in range(self.size - 1)\n",
        "            if self.apply_action(state, (1 + orient, (row, col)), player) is not None\n",
        "        ]\n",
        "        return moves + walls\n",
        "\n",
        "    def has_player_won(self, state, player):\n",
        "        \"\"\"\n",
        "        Checks if the player has reached their goal row.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            player (int): Player index (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the player has won, False otherwise.\n",
        "        \"\"\"\n",
        "        return state.player_locations[player][0] == (self.size - 1) * (1 - player)\n",
        "\n",
        "    def calculate_draw_score(self, state, player):\n",
        "        \"\"\"\n",
        "        Computes a heuristic score for a draw based on shortest paths.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            player (int): Player index (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            float: Draw score based on path lengths.\n",
        "        \"\"\"\n",
        "        player_path = self._find_shortest_path(state, player)\n",
        "        opponent_path = self._find_shortest_path(state, 1 - player)\n",
        "        return player_path / (player_path + opponent_path)\n",
        "\n",
        "    def evaluate_state(self, state, player, turns):\n",
        "        \"\"\"\n",
        "        Determines if the game is over and assigns a value.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            player (int): Player index (0 or 1).\n",
        "            turns (int): Number of turns played.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (is_terminal, is_draw, value).\n",
        "        \"\"\"\n",
        "        if turns > 50:\n",
        "            return True, True, self.calculate_draw_score(state, player)\n",
        "        if self.has_player_won(state, player):\n",
        "            return True, False, 1\n",
        "        return False, False, 0\n",
        "\n",
        "def parse_command(command):\n",
        "    \"\"\"\n",
        "    Parses a command string into an action tuple.\n",
        "\n",
        "    Args:\n",
        "        command (str): Command string (e.g., \"move 2 3\" or \"wall 0 1 2\").\n",
        "\n",
        "    Returns:\n",
        "        tuple: Action type and value.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the command is invalid.\n",
        "    \"\"\"\n",
        "    parts = command.split()\n",
        "    if parts[0] == 'move':\n",
        "        return 0, (int(parts[1]), int(parts[2]))\n",
        "    elif parts[0] == 'wall':\n",
        "        return 1 + int(parts[1]), (int(parts[2]), int(parts[3]))\n",
        "    raise ValueError('Invalid command')\n",
        "\n",
        "# Module 3: SearchNode\n",
        "# Description: Represents a node in the Monte Carlo Tree Search (MCTS) tree.\n",
        "# Purpose: Stores game state, actions, and statistics for MCTS exploration and selection.\n",
        "class SearchNode:\n",
        "    \"\"\"\n",
        "    A node in the MCTS tree for Quoridor.\n",
        "\n",
        "    Attributes:\n",
        "        game (QuoridorGame): Game rule manager.\n",
        "        config (dict): MCTS configuration parameters.\n",
        "        state (GameBoardState): Current game state.\n",
        "        player (int): Current player.\n",
        "        turn_count (int): Number of turns.\n",
        "        parent (SearchNode): Parent node.\n",
        "        action_performed (tuple): Action leading to this node.\n",
        "        children (list): Child nodes.\n",
        "        available_actions (list): Valid actions not yet expanded.\n",
        "        visits (int): Number of visits to this node.\n",
        "        value_sum (float): Sum of values from simulations.\n",
        "    \"\"\"\n",
        "    def __init__(self, game, config, state, player, turn_count, parent=None, action_performed=None):\n",
        "        self.game = game\n",
        "        self.config = config\n",
        "        self.state = state\n",
        "        self.player = player\n",
        "        self.turn_count = turn_count\n",
        "        self.parent = parent\n",
        "        self.action_performed = action_performed\n",
        "        self.children = []\n",
        "        self.available_actions = self.game.get_available_actions(self.state, self.player)\n",
        "        self.visits = 0\n",
        "        self.value_sum = 0\n",
        "\n",
        "    def is_expanded(self):\n",
        "        \"\"\"\n",
        "        Checks if all actions have been expanded.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if fully expanded, False otherwise.\n",
        "        \"\"\"\n",
        "        return len(self.available_actions) == 0 and len(self.children) > 0\n",
        "\n",
        "    def select_child(self):\n",
        "        \"\"\"\n",
        "        Selects the child node with the highest UCB score.\n",
        "\n",
        "        Returns:\n",
        "            SearchNode: Best child node.\n",
        "        \"\"\"\n",
        "        best_child, best_score = None, -np.inf\n",
        "        for child in self.children:\n",
        "            score = self._compute_ucb(child)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_child = child\n",
        "        return best_child\n",
        "\n",
        "    def _compute_ucb(self, child):\n",
        "        \"\"\"\n",
        "        Computes the UCB score for a child node.\n",
        "\n",
        "        Args:\n",
        "            child (SearchNode): Child node.\n",
        "\n",
        "        Returns:\n",
        "            float: UCB score.\n",
        "        \"\"\"\n",
        "        q_value = child.value_sum / (child.visits + 1e-5)\n",
        "        exploration = self.config['C'] * math.sqrt(math.log(self.visits + 1) / (child.visits + 1e-5))\n",
        "        return q_value + exploration\n",
        "\n",
        "    def expand_node(self):\n",
        "        \"\"\"\n",
        "        Expands the node by creating a child for a random unexpanded action.\n",
        "\n",
        "        Returns:\n",
        "            SearchNode: New child node.\n",
        "        \"\"\"\n",
        "        action = random.choice(self.available_actions)\n",
        "        self.available_actions.remove(action)\n",
        "        child_state = self.game.apply_action(self.state, action, self.player)\n",
        "        child = SearchNode(self.game, self.config, child_state, 1 - self.player, self.turn_count + 1, self, action)\n",
        "        self.children.append(child)\n",
        "        return child\n",
        "\n",
        "    def run_simulation(self):\n",
        "        \"\"\"\n",
        "        Performs a random rollout simulation from the current state.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (is_draw, value).\n",
        "        \"\"\"\n",
        "        current_state = self.state.duplicate()\n",
        "        current_player = self.player\n",
        "        current_turns = self.turn_count\n",
        "        while True:\n",
        "            is_terminal, is_draw, value = self.game.evaluate_state(current_state, current_player, current_turns)\n",
        "            if is_terminal:\n",
        "                return is_draw, value\n",
        "            current_player = 1 - current_player\n",
        "            actions = self.game.get_available_actions(current_state, current_player)\n",
        "            action = random.choice(actions)\n",
        "            current_state = self.game.apply_action(current_state, action, current_player)\n",
        "            current_turns += 1\n",
        "\n",
        "    def backpropagate(self, value, is_draw):\n",
        "        \"\"\"\n",
        "        Updates node statistics and propagates values up the tree.\n",
        "\n",
        "        Args:\n",
        "            value (float): Simulation value.\n",
        "            is_draw (bool): Whether the result is a draw.\n",
        "        \"\"\"\n",
        "        self.visits += 1\n",
        "        self.value_sum += value * self.config['draw_discount'] if is_draw else value\n",
        "        if self.parent:\n",
        "            self.parent.backpropagate(value, is_draw)\n",
        "\n",
        "# Module 4: MCTSSearch\n",
        "# Description: Implements Monte Carlo Tree Search for Quoridor.\n",
        "# Purpose: Performs MCTS to select the best action by exploring the game tree.\n",
        "class MCTSSearch:\n",
        "    \"\"\"\n",
        "    Monte Carlo Tree Search implementation for Quoridor.\n",
        "\n",
        "    Attributes:\n",
        "        game (QuoridorGame): Game rule manager.\n",
        "        config (dict): MCTS configuration parameters.\n",
        "    \"\"\"\n",
        "    def __init__(self, game, config):\n",
        "        self.game = game\n",
        "        self.config = config\n",
        "\n",
        "    def perform_search(self, state, player):\n",
        "        \"\"\"\n",
        "        Runs MCTS to compute action probabilities.\n",
        "\n",
        "        Args:\n",
        "            state (GameBoardState): Current game state.\n",
        "            player (int): Current player.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (actions, probabilities).\n",
        "        \"\"\"\n",
        "        root = SearchNode(self.game, self.config, state, player, 0)\n",
        "        for _ in tqdm.tqdm(range(self.config['N'])):\n",
        "            node = root\n",
        "            while node.is_expanded():\n",
        "                node = node.select_child()\n",
        "            is_terminal, is_draw, value = self.game.evaluate_state(node.state, 1 - node.player, node.turn_count)\n",
        "            if not is_terminal:\n",
        "                node = node.expand_node()\n",
        "                is_draw, value = node.run_simulation()\n",
        "            node.backpropagate(value, is_draw)\n",
        "        actions = [child.action_performed for child in root.children]\n",
        "        probabilities = np.array([child.value_sum / (child.visits + 1e-5) for child in root.children])\n",
        "        print('Node stats:', [(child.visits, child.value_sum) for child in root.children])\n",
        "        probabilities /= probabilities.sum()\n",
        "        return actions, probabilities\n",
        "\n",
        "# Module 5: ResidualBlock\n",
        "# Description: Defines a residual block for the neural network.\n",
        "# Purpose: Provides a building block for the Quoridor neural network to learn features.\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual block for the Quoridor neural network.\n",
        "\n",
        "    Attributes:\n",
        "        conv1 (nn.Conv2d): First convolutional layer.\n",
        "        bn1 (nn.BatchNorm2d): First batch normalization layer.\n",
        "        conv2 (nn.Conv2d): Second convolutional layer.\n",
        "        bn2 (nn.BatchNorm2d): Second batch normalization layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the residual block.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with residual connection.\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        return F.relu(x)\n",
        "\n",
        "# Module 6: QuoridorNeuralNet\n",
        "# Description: Defines the neural network for Quoridor, predicting policy and value.\n",
        "# Purpose: Provides a deep learning model to guide MCTS by estimating action probabilities and state values.\n",
        "class QuoridorNeuralNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network for Quoridor, predicting policy and value.\n",
        "\n",
        "    Attributes:\n",
        "        initial_block (nn.Sequential): Initial convolutional block.\n",
        "        backbone (nn.Sequential): Stack of residual blocks.\n",
        "        policy_output (nn.Sequential): Policy head for action probabilities.\n",
        "        value_output (nn.Sequential): Value head for state evaluation.\n",
        "    \"\"\"\n",
        "    def __init__(self, game, num_residuals, channels):\n",
        "        super().__init__()\n",
        "        self.initial_block = nn.Sequential(\n",
        "            nn.Conv2d(4, channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.backbone = nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [(f'residual_{i}', ResidualBlock(channels)) for i in range(num_residuals)]\n",
        "            )\n",
        "        )\n",
        "        self.policy_output = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 1, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels, 3, 3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.value_output = nn.Sequential(\n",
        "            nn.Conv2d(channels, 3, 1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * game.size * game.size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor (4xNxN).\n",
        "\n",
        "        Returns:\n",
        "            tuple: (policy, value) tensors.\n",
        "        \"\"\"\n",
        "        x = self.initial_block(x)\n",
        "        x = self.backbone(x)\n",
        "        policy = self.policy_output(x)\n",
        "        value = self.value_output(x)\n",
        "        return policy, value\n",
        "\n",
        "# Example Usage and Visualization\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize game and state\n",
        "    game = QuoridorGame(5, 1)\n",
        "    state = game.create_initial_state()\n",
        "\n",
        "    # Test neural network\n",
        "    model = QuoridorNeuralNet(game, 3, 10)\n",
        "    input_tensor = torch.tensor(state.encode_state(0)).unsqueeze(0)\n",
        "    policy, value = model(input_tensor)\n",
        "    print(f\"Predicted value: {value}\")\n",
        "\n",
        "    # Visualize policy\n",
        "    plt.figure()\n",
        "    plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), 5, 5, fc='w', ec='k'))\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            rate = float(policy[0, 0, i, j])\n",
        "            color = np.array([1 - rate, 0, rate, 1])\n",
        "            plt.gca().add_patch(plt.Rectangle((i - 0.3, j - 0.3), 0.6, 0.6, fc=color, ec='k'))\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            rate = float(policy[0, 0, i, j])\n",
        "            color = np.array([1 - rate, 0, rate, 1])\n",
        "            plt.gca().add_patch(plt.Rectangle((i + 0.5 - 0.5, j + 0.5 - 0.1), 1, 0.2, fc=color, ec='k'))\n",
        "            plt.gca().add_patch(plt.Rectangle((i + 0.5 - 0.1, j + 0.5 - 0.5), 0.2, 1, fc=color, ec='k'))\n",
        "    plt.gca().add_patch(plt.Circle((state.player_locations[0, 0], state.player_locations[0, 1]), 0.1, fc='w', ec='k'))\n",
        "    plt.gca().add_patch(plt.Circle((state.player_locations[1, 0], state.player_locations[1, 1]), 0.1, fc='k', ec='k'))\n",
        "    plt.axis('scaled')\n",
        "    plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}